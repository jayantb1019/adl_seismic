{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "FILEPATH = '../notebooks/dataset_quality_report.xlsx'\n",
    "qdf_i = pd.read_excel(FILEPATH,sheet_name='interpretation' )\n",
    "qdf_f = pd.read_excel(FILEPATH,sheet_name='faciesmark' )\n",
    "qdf_s = pd.read_excel(FILEPATH,sheet_name='stdata12' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf_i.columns = list(map(lambda x : x.strip(), qdf_i.columns))\n",
    "qdf_f.columns = list(map(lambda x : x.strip(), qdf_f.columns))\n",
    "qdf_s.columns = list(map(lambda x : x.strip(), qdf_s.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Inline No.', 'No data', 'Small acquisition Gaps',\n",
       "       'Large Acquisition Gaps', 'Label Misalignment', '>30% No data',\n",
       "       'Random High Noise', 'Unnamed: 7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf_i.columns = list(map(lambda x : x.strip(), qdf_i.columns))\n",
    "qdf_i.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.47311827956989"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no data \n",
    "qdf_i['No data'].sum() / qdf_i.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = qdf_i['No data'] == 1 \n",
    "qdf_i[~condition]['Inline No.'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small acquisition gaps \n",
    "qdf_i['Small acquisition Gaps'].sum() / qdf_i.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.715821812596005"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf_i['Large Acquisition Gaps'].sum() / qdf_i.shape[0] * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 108, 116, 117, 118, 119, 120, 121, 122, 123, 135, 149, 150, 151, 152, 153, 154, 155, 167, 184, 186, 196, 216, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 249, 251, 252, 263, 264, 266, 276, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 304, 305, 306, 307, 308, 309, 310, 311, 312, 319, 320, 321, 322, 323, 324, 328, 329, 330, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 371, 392, 400, 443, 444, 465, 468, 469, 470, 471, 472, 476, 480, 488, 505, 508, 513, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 573, 575, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 652, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750]\n"
     ]
    }
   ],
   "source": [
    "condition = qdf_i['Large Acquisition Gaps'] == 1\n",
    "print(qdf_i[condition]['Inline No.'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.680491551459294"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "qdf_i['>30% No data'].sum() / qdf_i.shape[0] * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.680491551459294"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "qdf_i['Label Misalignment'].sum() / qdf_i.shape[0] * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750]\n"
     ]
    }
   ],
   "source": [
    "cond = qdf_i['Label Misalignment'] == 1\n",
    "print(qdf_i[cond]['Inline No.'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# inlines with 30% missing values \n",
    "cond_miss = qdf_i['>30% No data'] == 1\n",
    "print(qdf_i[cond_miss]['Inline No.'].to_list())\n",
    "print(len(qdf_i[cond_miss]['Inline No.'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the datasets , original paths\n",
    "\n",
    "# interpretation\n",
    "INTERPRETATION_VOL_PATH = '../data/f3_interpretation/inline_vol.npy'\n",
    "INTERPRETATION_LABEL_PATH = '../data/f3_interpretation/inline_label.npy'\n",
    "\n",
    "# faciesmark dataset \n",
    "FACIESMARK_VOL_PATH = '../data/faciesmark/raw/seismic_entire_volume.npy'\n",
    "FACIESMARK_LABEL_PATH = '../data/faciesmark/raw/labels_entire_volume.npy'\n",
    "\n",
    "\n",
    "# stdata12 dataset \n",
    "STDATA_VOL_PATH = '../data/stdata12/stdata_12_amplitude.npy'\n",
    "STDATA_LABEL_PATH = '../data/stdata12/stdata_12_labels.npy'\n",
    "\n",
    "\n",
    "## cleaned dataset paths \n",
    "\n",
    "# interpretation\n",
    "INTERPRETATION_VOL_PATH_CLEAN = '../data/clean/f3_interpretation/inline_vol.npy'\n",
    "INTERPRETATION_LABEL_PATH_CLEAN = '../data/clean/f3_interpretation/inline_label.npy'\n",
    "\n",
    "# faciesmark dataset \n",
    "FACIESMARK_VOL_PATH_CLEAN = '../data/clean/faciesmark/raw/seismic_entire_volume.npy'\n",
    "FACIESMARK_LABEL_PATH_CLEAN = '../data/clean/faciesmark/raw/labels_entire_volume.npy'\n",
    "\n",
    "\n",
    "# stdata12 dataset \n",
    "STDATA_VOL_PATH_CLEAN = '../data/clean/stdata12/stdata_12_amplitude.npy'\n",
    "STDATA_LABEL_PATH_CLEAN = '../data/clean/stdata12/stdata_12_labels.npy'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Label Misalignment'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Label Misalignment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((651, 951, 462), (651, 951, 462))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning interpretation \n",
    "import numpy as np \n",
    "inter_vol = np.load(INTERPRETATION_VOL_PATH)\n",
    "inter_labels = np.load(INTERPRETATION_LABEL_PATH)\n",
    "\n",
    "inter_vol.shape, inter_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(651, 951, 361)\n",
      "(651, 951, 361)\n"
     ]
    }
   ],
   "source": [
    "# removing the first 100 twt samples \n",
    "inter_vol_twt = inter_vol[:,:,101:]\n",
    "print(inter_vol_twt.shape)\n",
    "\n",
    "inter_labels_twt = inter_labels[:,:,101:]\n",
    "print(inter_labels_twt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 951, 361), (601, 951, 361))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing inlines with > 30% '0' \n",
    "# last 50 inlines \n",
    "inter_vol_miss = inter_vol_twt[:601,:,:]\n",
    "inter_labels_miss = inter_labels_twt[:601,:,:]\n",
    "\n",
    "inter_vol_miss.shape, inter_labels_miss.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to numpy  \n",
    "np.save(INTERPRETATION_VOL_PATH_CLEAN, inter_vol_miss)\n",
    "np.save(INTERPRETATION_LABEL_PATH_CLEAN , inter_labels_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(inter_labels_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faciesmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((599, 901, 255), (599, 901, 255))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## faciesmark \n",
    "import numpy as np\n",
    "\n",
    "facies_vol = np.load(FACIESMARK_VOL_PATH)\n",
    "facies_label  = np.load(FACIESMARK_LABEL_PATH)\n",
    "\n",
    "facies_vol.shape, facies_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((597, 901, 255), (597, 901, 255))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the last two inlines containing random high noise \n",
    "facies_vol_clean = facies_vol[:-2, :, : ]\n",
    "facies_label_clean = facies_label[:-2 , : , : ]\n",
    "\n",
    "facies_vol_clean.shape, facies_label_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to clean path \n",
    "np.save(FACIESMARK_VOL_PATH_CLEAN, facies_vol_clean)\n",
    "np.save(FACIESMARK_LABEL_PATH_CLEAN, facies_label_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels \n",
    "np.unique(facies_label_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stdata-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/stdata12/stdata_12_amplitude.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stdata_vol \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(STDATA_VOL_PATH)\n\u001b[1;32m      2\u001b[0m stdata_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(STDATA_LABEL_PATH)\n\u001b[1;32m      4\u001b[0m stdata_label\u001b[39m.\u001b[39mshape, stdata_vol\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/root/anaconda3/envs/lightning/lib/python3.9/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/stdata12/stdata_12_amplitude.npy'"
     ]
    }
   ],
   "source": [
    "stdata_vol = np.load(STDATA_VOL_PATH)\n",
    "stdata_label = np.load(STDATA_LABEL_PATH)\n",
    "\n",
    "stdata_label.shape, stdata_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 951, 362), (4, 951, 362))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the first 100 twt \n",
    "stdata_vol_twt = stdata_vol[:,:,101:]\n",
    "stdata_label_twt  = stdata_label[:,:,101:]\n",
    "\n",
    "stdata_vol_twt.shape, stdata_label_twt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(stdata_label_twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to clean paths \n",
    "np.save(STDATA_VOL_PATH_CLEAN, stdata_vol_twt)\n",
    "np.save(STDATA_LABEL_PATH_CLEAN, stdata_label_twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b09cd0fb50ff65360a95b6ae989c90472b6f8f24fcb7acdc1d5c638e9f7df11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
